#!/bin/bash

# BookedBarber V2 - Performance Regression Hook
# Monitors performance metrics to prevent regressions
# 
# Usage: This hook runs automatically on git commit
# Can be bypassed with: git commit --no-verify

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
BACKEND_DIR="backend-v2"
FRONTEND_DIR="backend-v2/frontend-v2"
PERFORMANCE_DIR="monitoring"
MAX_RETRIES=3
TIMEOUT=120

# Performance thresholds
MAX_BUNDLE_SIZE_INCREASE_PERCENT=10
MAX_API_RESPONSE_TIME_MS=2000
MAX_API_RESPONSE_INCREASE_MS=200
MAX_DATABASE_QUERY_TIME_MS=500
BASELINE_FILE="$PERFORMANCE_DIR/performance_baseline.json"

# Log function
log() {
    echo -e "${BLUE}[PERFORMANCE]${NC} $1"
}

error() {
    echo -e "${RED}[PERFORMANCE ERROR]${NC} $1"
}

success() {
    echo -e "${GREEN}[PERFORMANCE SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[PERFORMANCE WARNING]${NC} $1"
}

# Check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Run command with timeout and retries
run_with_timeout() {
    local cmd="$1"
    local desc="$2"
    local retries=0
    
    while [[ $retries -lt $MAX_RETRIES ]]; do
        log "Running $desc (attempt $((retries + 1))/$MAX_RETRIES)..."
        
        if timeout $TIMEOUT bash -c "$cmd" 2>/dev/null; then
            return 0
        fi
        
        retries=$((retries + 1))
        if [[ $retries -lt $MAX_RETRIES ]]; then
            warning "$desc failed, retrying in 2 seconds..."
            sleep 2
        fi
    done
    
    return 1
}

# Get bundle size information
get_bundle_size() {
    local build_dir="$1"
    
    if [[ ! -d "$build_dir" ]]; then
        echo "0"
        return
    fi
    
    # Get total size of JS and CSS files in KB
    find "$build_dir" -name "*.js" -o -name "*.css" | xargs stat -c%s 2>/dev/null | awk '{sum+=$1} END {print int(sum/1024)}' || echo "0"
}

# Test API response times
test_api_performance() {
    local backend_running=false
    
    # Check if backend is running
    if curl -s "http://localhost:8000/health" >/dev/null 2>&1; then
        backend_running=true
    elif curl -s "http://localhost:8000/docs" >/dev/null 2>&1; then
        backend_running=true
    fi
    
    if [[ "$backend_running" != true ]]; then
        echo "API_NOT_RUNNING"
        return
    fi
    
    # Test common endpoints
    local endpoints=(
        "/health"
        "/api/v1/auth/me"
        "/api/v1/appointments"
        "/api/v1/barbers"
        "/api/v1/services"
    )
    
    local total_time=0
    local tested_endpoints=0
    local max_time=0
    
    for endpoint in "${endpoints[@]}"; do
        # Use curl to measure response time
        local response_time=$(curl -w "%{time_total}" -s -o /dev/null "http://localhost:8000$endpoint" 2>/dev/null || echo "999")
        
        if [[ "$response_time" != "999" ]]; then
            # Convert to milliseconds
            local time_ms=$(echo "$response_time * 1000" | bc 2>/dev/null || echo "999")
            
            if [[ "$time_ms" != "999" ]]; then
                total_time=$(echo "$total_time + $time_ms" | bc 2>/dev/null || echo "$total_time")
                tested_endpoints=$((tested_endpoints + 1))
                
                # Track maximum response time
                if (( $(echo "$time_ms > $max_time" | bc -l 2>/dev/null || echo 0) )); then
                    max_time=$time_ms
                fi
            fi
        fi
    done
    
    if [[ $tested_endpoints -gt 0 ]]; then
        local avg_time=$(echo "scale=2; $total_time / $tested_endpoints" | bc 2>/dev/null || echo "0")
        echo "AVERAGE:$avg_time,MAX:$max_time,TESTED:$tested_endpoints"
    else
        echo "API_TEST_FAILED"
    fi
}

# Test database query performance
test_database_performance() {
    if [[ ! -f "$BACKEND_DIR/main.py" ]]; then
        echo "DB_TEST_UNAVAILABLE"
        return
    fi
    
    # Simple database performance test
    local db_test_script="
import time
import sys
import os
sys.path.append('$BACKEND_DIR')

try:
    from database import get_db
    from sqlalchemy import text
    
    db = next(get_db())
    
    # Test a simple query
    start_time = time.time()
    result = db.execute(text('SELECT 1'))
    query_time = (time.time() - start_time) * 1000
    
    print(f'QUERY_TIME:{query_time:.2f}')
except Exception as e:
    print(f'DB_ERROR:{str(e)}')
"
    
    cd "$BACKEND_DIR" && python3 -c "$db_test_script" 2>/dev/null || echo "DB_TEST_FAILED"
}

# Check for performance-impacting code patterns
check_code_patterns() {
    local files=("$@")
    local performance_issues=()
    
    for file in "${files[@]}"; do
        if [[ ! -f "$file" ]]; then
            continue
        fi
        
        # Check for common performance anti-patterns
        if [[ "$file" =~ \.py$ ]]; then
            # Python performance patterns
            if grep -q "SELECT \*" "$file"; then
                performance_issues+=("$file: SELECT * query detected")
            fi
            
            if grep -q -E "\.all\(\)\s*$" "$file"; then
                performance_issues+=("$file: .all() without limit detected")
            fi
            
            if grep -q "N+1" "$file" || grep -q -E "for.*in.*\.(query|filter)" "$file"; then
                performance_issues+=("$file: Potential N+1 query pattern")
            fi
        fi
        
        if [[ "$file" =~ \.(tsx?|jsx?)$ ]]; then
            # JavaScript/TypeScript performance patterns
            if grep -q -E "useEffect\(\s*\(\)\s*=>" "$file" && ! grep -q -A5 "useEffect" "$file" | grep -q "\[\]"; then
                performance_issues+=("$file: useEffect without dependency array")
            fi
            
            if grep -q -E "\.map\(.*\.map\(" "$file"; then
                performance_issues+=("$file: Nested .map() calls detected")
            fi
            
            if grep -q "document.getElementById" "$file" || grep -q "document.querySelector" "$file"; then
                performance_issues+=("$file: Direct DOM queries in React component")
            fi
        fi
    done
    
    for issue in "${performance_issues[@]}"; do
        echo "PATTERN_ISSUE:$issue"
    done
}

# Load performance baseline
load_baseline() {
    if [[ -f "$BASELINE_FILE" ]]; then
        cat "$BASELINE_FILE"
    else
        echo "{}"
    fi
}

# Save performance baseline
save_baseline() {
    local data="$1"
    
    mkdir -p "$PERFORMANCE_DIR"
    echo "$data" > "$BASELINE_FILE"
}

# Get list of staged files
STAGED_FILES=$(git diff --cached --name-only --diff-filter=ACMR)

if [[ -z "$STAGED_FILES" ]]; then
    log "No staged files to check"
    exit 0
fi

log "Starting performance regression check..."

PERFORMANCE_ISSUES=0
FRONTEND_CHANGES=false
BACKEND_CHANGES=false
MODIFIED_FILES=()

# Check what types of files were modified
while IFS= read -r file; do
    if [[ -z "$file" ]]; then
        continue
    fi
    
    MODIFIED_FILES+=("$file")
    
    if [[ "$file" =~ ^$FRONTEND_DIR/ ]]; then
        FRONTEND_CHANGES=true
    fi
    
    if [[ "$file" =~ ^$BACKEND_DIR/ ]] && [[ ! "$file" =~ ^$FRONTEND_DIR/ ]]; then
        BACKEND_CHANGES=true
    fi
done <<< "$STAGED_FILES"

# Load baseline performance data
BASELINE_DATA=$(load_baseline)

# Check code patterns for performance issues
log "Checking for performance anti-patterns..."
PATTERN_ISSUES=$(check_code_patterns "${MODIFIED_FILES[@]}")

if [[ -n "$PATTERN_ISSUES" ]]; then
    warning "Performance anti-patterns detected:"
    echo "$PATTERN_ISSUES" | grep "PATTERN_ISSUE:" | sed 's/PATTERN_ISSUE:/  ⚠️  /'
fi

# Frontend performance checks
if [[ "$FRONTEND_CHANGES" == true ]]; then
    log "Frontend changes detected, checking bundle size..."
    
    if [[ -d "$FRONTEND_DIR" ]] && command_exists npm; then
        # Try to build the frontend to check bundle size
        BUILD_CMD="cd $FRONTEND_DIR && npm run build"
        
        if run_with_timeout "$BUILD_CMD" "Frontend build"; then
            # Get current bundle size
            CURRENT_BUNDLE_SIZE=$(get_bundle_size "$FRONTEND_DIR/.next" 2>/dev/null || get_bundle_size "$FRONTEND_DIR/dist" 2>/dev/null || echo "0")
            
            if [[ "$CURRENT_BUNDLE_SIZE" -gt 0 ]]; then
                # Compare with baseline
                BASELINE_BUNDLE_SIZE=$(echo "$BASELINE_DATA" | python3 -c "
import json
import sys
try:
    data = json.load(sys.stdin)
    print(data.get('bundle_size_kb', 0))
except:
    print(0)
" 2>/dev/null || echo "0")
                
                if [[ "$BASELINE_BUNDLE_SIZE" -gt 0 ]]; then
                    BUNDLE_INCREASE=$(( CURRENT_BUNDLE_SIZE - BASELINE_BUNDLE_SIZE ))
                    BUNDLE_INCREASE_PERCENT=$(( (BUNDLE_INCREASE * 100) / BASELINE_BUNDLE_SIZE ))
                    
                    if [[ $BUNDLE_INCREASE_PERCENT -gt $MAX_BUNDLE_SIZE_INCREASE_PERCENT ]]; then
                        error "Bundle size increased by ${BUNDLE_INCREASE_PERCENT}% (${BUNDLE_INCREASE}KB)"
                        error "Current: ${CURRENT_BUNDLE_SIZE}KB, Baseline: ${BASELINE_BUNDLE_SIZE}KB"
                        PERFORMANCE_ISSUES=$((PERFORMANCE_ISSUES + 1))
                    else
                        success "Bundle size check passed (${BUNDLE_INCREASE_PERCENT}% increase)"
                    fi
                else
                    warning "No baseline bundle size found, setting current as baseline"
                    log "Current bundle size: ${CURRENT_BUNDLE_SIZE}KB"
                fi
                
                # Update baseline
                UPDATED_BASELINE=$(echo "$BASELINE_DATA" | python3 -c "
import json
import sys
try:
    data = json.load(sys.stdin)
except:
    data = {}
data['bundle_size_kb'] = $CURRENT_BUNDLE_SIZE
data['last_bundle_check'] = '$(date -u +%Y-%m-%dT%H:%M:%SZ)'
print(json.dumps(data, indent=2))
")
                save_baseline "$UPDATED_BASELINE"
            fi
        else
            warning "Could not build frontend to check bundle size"
        fi
    else
        warning "Frontend directory not found or npm not available"
    fi
fi

# Backend performance checks
if [[ "$BACKEND_CHANGES" == true ]]; then
    log "Backend changes detected, checking API performance..."
    
    # Test API performance
    API_PERFORMANCE=$(test_api_performance)
    
    if [[ "$API_PERFORMANCE" =~ ^AVERAGE: ]]; then
        # Extract performance metrics
        AVG_TIME=$(echo "$API_PERFORMANCE" | grep -o "AVERAGE:[0-9.]*" | cut -d: -f2)
        MAX_TIME=$(echo "$API_PERFORMANCE" | grep -o "MAX:[0-9.]*" | cut -d: -f2)
        
        log "API Performance - Average: ${AVG_TIME}ms, Max: ${MAX_TIME}ms"
        
        # Check against thresholds
        if (( $(echo "$MAX_TIME > $MAX_API_RESPONSE_TIME_MS" | bc -l 2>/dev/null || echo 0) )); then
            error "API response time too high: ${MAX_TIME}ms (max: ${MAX_API_RESPONSE_TIME_MS}ms)"
            PERFORMANCE_ISSUES=$((PERFORMANCE_ISSUES + 1))
        fi
        
        # Compare with baseline
        BASELINE_AVG=$(echo "$BASELINE_DATA" | python3 -c "
import json
import sys
try:
    data = json.load(sys.stdin)
    print(data.get('api_avg_response_ms', 0))
except:
    print(0)
" 2>/dev/null || echo "0")
        
        if [[ "$BASELINE_AVG" != "0" ]]; then
            RESPONSE_INCREASE=$(echo "$AVG_TIME - $BASELINE_AVG" | bc 2>/dev/null || echo "0")
            
            if (( $(echo "$RESPONSE_INCREASE > $MAX_API_RESPONSE_INCREASE_MS" | bc -l 2>/dev/null || echo 0) )); then
                error "API response time increased by ${RESPONSE_INCREASE}ms"
                error "Current: ${AVG_TIME}ms, Baseline: ${BASELINE_AVG}ms"
                PERFORMANCE_ISSUES=$((PERFORMANCE_ISSUES + 1))
            fi
        fi
        
        # Update baseline
        UPDATED_BASELINE=$(echo "$BASELINE_DATA" | python3 -c "
import json
import sys
try:
    data = json.load(sys.stdin)
except:
    data = {}
data['api_avg_response_ms'] = float('$AVG_TIME')
data['api_max_response_ms'] = float('$MAX_TIME')
data['last_api_check'] = '$(date -u +%Y-%m-%dT%H:%M:%SZ)'
print(json.dumps(data, indent=2))
")
        save_baseline "$UPDATED_BASELINE"
        
    elif [[ "$API_PERFORMANCE" == "API_NOT_RUNNING" ]]; then
        warning "Backend server not running, skipping API performance test"
        warning "Start server with: cd $BACKEND_DIR && uvicorn main:app --reload"
    else
        warning "Could not test API performance"
    fi
    
    # Test database performance if available
    log "Testing database performance..."
    DB_PERFORMANCE=$(test_database_performance)
    
    if [[ "$DB_PERFORMANCE" =~ ^QUERY_TIME: ]]; then
        QUERY_TIME=$(echo "$DB_PERFORMANCE" | cut -d: -f2)
        log "Database query time: ${QUERY_TIME}ms"
        
        if (( $(echo "$QUERY_TIME > $MAX_DATABASE_QUERY_TIME_MS" | bc -l 2>/dev/null || echo 0) )); then
            warning "Database query time high: ${QUERY_TIME}ms (max: ${MAX_DATABASE_QUERY_TIME_MS}ms)"
        fi
    elif [[ "$DB_PERFORMANCE" =~ ^DB_ERROR: ]]; then
        warning "Database performance test failed: $(echo "$DB_PERFORMANCE" | cut -d: -f2-)"
    else
        warning "Could not test database performance"
    fi
fi

# Report results
if [[ $PERFORMANCE_ISSUES -gt 0 ]]; then
    error "Performance regressions detected!"
    echo
    echo -e "${YELLOW}Performance optimization suggestions:${NC}"
    echo
    
    if [[ "$FRONTEND_CHANGES" == true ]]; then
        echo -e "${YELLOW}Frontend optimizations:${NC}"
        echo "  • Analyze bundle with: npm run analyze"
        echo "  • Check for unused imports and dependencies"
        echo "  • Use dynamic imports for large components"
        echo "  • Optimize images and assets"
        echo "  • Enable tree shaking and code splitting"
        echo "  • Use React.memo() for expensive components"
        echo
    fi
    
    if [[ "$BACKEND_CHANGES" == true ]]; then
        echo -e "${YELLOW}Backend optimizations:${NC}"
        echo "  • Use database indexes for frequently queried fields"
        echo "  • Implement query pagination with LIMIT/OFFSET"
        echo "  • Use select_related() and prefetch_related() for joins"
        echo "  • Add database connection pooling"
        echo "  • Cache frequently accessed data"
        echo "  • Profile slow endpoints with debugging tools"
        echo
    fi
    
    echo -e "${YELLOW}General performance best practices:${NC}"
    echo "  • Avoid N+1 queries"
    echo "  • Use efficient data structures"
    echo "  • Implement proper caching strategies"
    echo "  • Monitor performance metrics in production"
    echo "  • Set up performance budgets"
    echo
    echo -e "${YELLOW}Performance monitoring tools:${NC}"
    echo "  • Frontend: Lighthouse, Web Vitals, Bundle Analyzer"
    echo "  • Backend: cProfile, py-spy, SQLAlchemy query logging"
    echo "  • Database: EXPLAIN queries, pg_stat_statements"
    echo
    echo -e "${RED}To bypass this check (not recommended):${NC}"
    echo "  git commit --no-verify"
    echo
    exit 1
fi

# Show performance information even when passing
if [[ -n "$PATTERN_ISSUES" ]]; then
    warning "Consider reviewing the performance patterns mentioned above"
fi

success "All performance checks passed!"
log "Performance metrics within acceptable thresholds"
exit 0