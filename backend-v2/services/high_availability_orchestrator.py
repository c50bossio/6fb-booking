"""
High Availability Orchestrator for 6fb-booking Platform
Implements enterprise-grade high availability patterns for 99.9%+ uptime
with automatic failover, circuit breakers, and zero-downtime deployments
"""

import asyncio
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Union
from dataclasses import dataclass, field, asdict
from enum import Enum
import json
import statistics
from collections import defaultdict, deque

from services.redis_service import cache_service
from services.enhanced_sentry_monitoring import enhanced_sentry, AlertSeverity


logger = logging.getLogger(__name__)


class ServiceState(Enum):
    """Service availability states"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    FAILED = "failed"
    MAINTENANCE = "maintenance"


class FailoverState(Enum):
    """Failover mechanism states"""
    ACTIVE = "active"
    STANDBY = "standby"
    FAILED_OVER = "failed_over"
    RECOVERING = "recovering"
    DISABLED = "disabled"


class CircuitBreakerState(Enum):
    """Circuit breaker states"""
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing fast
    HALF_OPEN = "half_open"  # Testing recovery


@dataclass
class ServiceInstance:
    """Individual service instance configuration"""
    id: str
    name: str
    endpoint: str
    health_check_url: str
    priority: int  # Lower number = higher priority
    max_capacity: int
    current_load: float = 0.0
    state: ServiceState = ServiceState.HEALTHY
    last_health_check: Optional[datetime] = None
    consecutive_failures: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class CircuitBreaker:
    """Circuit breaker for service protection"""
    service_name: str
    state: CircuitBreakerState = CircuitBreakerState.CLOSED
    failure_count: int = 0
    success_count: int = 0
    last_failure_time: Optional[datetime] = None
    failure_threshold: int = 5
    success_threshold: int = 3
    timeout_seconds: int = 60
    half_open_max_calls: int = 3
    half_open_calls: int = 0
    
    def can_execute(self) -> bool:
        """Check if request can be executed"""
        if self.state == CircuitBreakerState.CLOSED:
            return True
        elif self.state == CircuitBreakerState.OPEN:
            if self.last_failure_time and \
               (datetime.utcnow() - self.last_failure_time).total_seconds() > self.timeout_seconds:
                self.state = CircuitBreakerState.HALF_OPEN
                self.half_open_calls = 0
                return True
            return False
        elif self.state == CircuitBreakerState.HALF_OPEN:
            return self.half_open_calls < self.half_open_max_calls
        return False
    
    def record_success(self):
        """Record successful execution"""
        if self.state == CircuitBreakerState.CLOSED:
            self.failure_count = 0
        elif self.state == CircuitBreakerState.HALF_OPEN:
            self.success_count += 1
            if self.success_count >= self.success_threshold:
                self.state = CircuitBreakerState.CLOSED
                self.failure_count = 0
                self.success_count = 0
    
    def record_failure(self):
        """Record failed execution"""
        self.failure_count += 1
        self.last_failure_time = datetime.utcnow()
        
        if self.state == CircuitBreakerState.CLOSED:
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitBreakerState.OPEN
        elif self.state == CircuitBreakerState.HALF_OPEN:
            self.state = CircuitBreakerState.OPEN
            self.half_open_calls = 0


@dataclass
class LoadBalancerPool:
    """Load balancer pool configuration"""
    name: str
    instances: List[ServiceInstance]
    balancing_strategy: str = "round_robin"  # round_robin, least_connections, weighted
    health_check_interval: int = 30
    sticky_sessions: bool = False
    session_affinity_key: Optional[str] = None
    current_index: int = 0
    
    def get_healthy_instances(self) -> List[ServiceInstance]:
        """Get list of healthy instances"""
        return [inst for inst in self.instances 
                if inst.state in [ServiceState.HEALTHY, ServiceState.DEGRADED]]
    
    def select_instance(self, session_key: Optional[str] = None) -> Optional[ServiceInstance]:
        """Select instance based on balancing strategy"""
        healthy_instances = self.get_healthy_instances()
        
        if not healthy_instances:
            return None
        
        if self.sticky_sessions and session_key:
            # Simple hash-based session affinity
            index = hash(session_key) % len(healthy_instances)
            return healthy_instances[index]
        
        if self.balancing_strategy == "round_robin":
            instance = healthy_instances[self.current_index % len(healthy_instances)]
            self.current_index = (self.current_index + 1) % len(healthy_instances)
            return instance
        
        elif self.balancing_strategy == "least_connections":
            return min(healthy_instances, key=lambda x: x.current_load)
        
        elif self.balancing_strategy == "weighted":
            # Select based on priority (lower number = higher priority)
            return min(healthy_instances, key=lambda x: x.priority)
        
        return healthy_instances[0]


@dataclass
class FailoverConfiguration:
    """Failover configuration for a service"""
    primary_pool: str
    secondary_pools: List[str]
    failover_threshold: int = 2  # Consecutive failures before failover
    auto_recovery_enabled: bool = True
    recovery_threshold: int = 3  # Consecutive successes before recovery
    health_check_interval: int = 15
    state: FailoverState = FailoverState.ACTIVE
    current_pool: Optional[str] = None
    failover_time: Optional[datetime] = None
    recovery_attempts: int = 0


class HighAvailabilityOrchestrator:
    """
    High Availability Orchestrator implementing enterprise patterns
    for 99.9%+ uptime with automatic failover and circuit breakers
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Service pools and instances
        self.load_balancer_pools: Dict[str, LoadBalancerPool] = {}
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        self.failover_configs: Dict[str, FailoverConfiguration] = {}
        
        # High availability patterns
        self.ha_patterns = self._initialize_ha_patterns()
        
        # Monitoring and metrics
        self.availability_metrics = defaultdict(lambda: deque(maxlen=1000))
        self.failover_history = deque(maxlen=100)
        self.circuit_breaker_events = deque(maxlen=500)
        
        # Configuration
        self.global_circuit_breaker_enabled = True
        self.auto_failover_enabled = True
        self.health_check_timeout = 5.0
        
        # Monitoring
        self._monitoring_active = False
        self._monitoring_tasks = []
        
        self.logger.info("ðŸ”„ High Availability Orchestrator initialized - targeting 99.9%+ uptime")
    
    def _initialize_ha_patterns(self) -> Dict[str, Dict[str, Any]]:
        """Initialize high availability patterns for critical services"""
        
        return {
            # Payment System HA Configuration
            "payment_system": {
                "pattern": "active_standby_with_circuit_breaker",
                "load_balancer": {
                    "strategy": "weighted",
                    "health_check_interval": 10,
                    "sticky_sessions": False
                },
                "circuit_breaker": {
                    "failure_threshold": 3,
                    "timeout_seconds": 30,
                    "success_threshold": 2
                },
                "failover": {
                    "auto_failover": True,
                    "failover_threshold": 2,
                    "recovery_threshold": 3
                },
                "instances": [
                    {
                        "id": "payment_primary",
                        "endpoint": "http://localhost:8000/api/v2/payments",
                        "health_check_url": "http://localhost:8000/api/v2/payments/health",
                        "priority": 1,
                        "max_capacity": 1000
                    },
                    {
                        "id": "payment_backup", 
                        "endpoint": "http://localhost:8001/api/v2/payments",
                        "health_check_url": "http://localhost:8001/api/v2/payments/health",
                        "priority": 2,
                        "max_capacity": 500
                    }
                ]
            },
            
            # Booking System HA Configuration
            "booking_system": {
                "pattern": "load_balanced_with_circuit_breaker",
                "load_balancer": {
                    "strategy": "round_robin",
                    "health_check_interval": 15,
                    "sticky_sessions": True,
                    "session_affinity_key": "user_id"
                },
                "circuit_breaker": {
                    "failure_threshold": 5,
                    "timeout_seconds": 60,
                    "success_threshold": 3
                },
                "instances": [
                    {
                        "id": "booking_1",
                        "endpoint": "http://localhost:8000/api/v2/appointments",
                        "health_check_url": "http://localhost:8000/api/v2/appointments/health",
                        "priority": 1,
                        "max_capacity": 2000
                    },
                    {
                        "id": "booking_2",
                        "endpoint": "http://localhost:8002/api/v2/appointments",
                        "health_check_url": "http://localhost:8002/api/v2/appointments/health",
                        "priority": 1,
                        "max_capacity": 2000
                    }
                ]
            },
            
            # AI Dashboard HA Configuration
            "ai_dashboard": {
                "pattern": "multi_instance_with_degraded_mode",
                "load_balancer": {
                    "strategy": "least_connections",
                    "health_check_interval": 20,
                    "sticky_sessions": False
                },
                "circuit_breaker": {
                    "failure_threshold": 4,
                    "timeout_seconds": 45,
                    "success_threshold": 2
                },
                "degraded_mode": {
                    "enabled": True,
                    "fallback_response": {
                        "message": "AI Dashboard operating in limited mode",
                        "features": ["basic_metrics", "cached_insights"],
                        "estimated_recovery": "5 minutes"
                    }
                },
                "instances": [
                    {
                        "id": "ai_dashboard_1",
                        "endpoint": "http://localhost:8000/api/v2/ai-dashboard",
                        "health_check_url": "http://localhost:8000/api/v2/ai-dashboard/health",
                        "priority": 1,
                        "max_capacity": 100
                    },
                    {
                        "id": "ai_dashboard_2",
                        "endpoint": "http://localhost:8003/api/v2/ai-dashboard",
                        "health_check_url": "http://localhost:8003/api/v2/ai-dashboard/health",
                        "priority": 2,
                        "max_capacity": 100
                    }
                ]
            },
            
            # Database HA Configuration
            "database": {
                "pattern": "primary_replica_with_automatic_failover",
                "load_balancer": {
                    "strategy": "read_write_split",
                    "health_check_interval": 10,
                    "sticky_sessions": False
                },
                "circuit_breaker": {
                    "failure_threshold": 2,
                    "timeout_seconds": 20,
                    "success_threshold": 1
                },
                "failover": {
                    "auto_failover": True,
                    "failover_threshold": 1,  # Immediate failover for database
                    "recovery_threshold": 2
                },
                "instances": [
                    {
                        "id": "db_primary",
                        "endpoint": "postgresql://localhost:5432/bookedbarber",
                        "health_check_url": "postgresql://localhost:5432/bookedbarber?select=1",
                        "priority": 1,
                        "max_capacity": 1000,
                        "role": "primary"
                    },
                    {
                        "id": "db_replica",
                        "endpoint": "postgresql://localhost:5433/bookedbarber",
                        "health_check_url": "postgresql://localhost:5433/bookedbarber?select=1",
                        "priority": 2,
                        "max_capacity": 800,
                        "role": "replica"
                    }
                ]
            },
            
            # External API Dependencies
            "stripe_api": {
                "pattern": "circuit_breaker_with_retry",
                "circuit_breaker": {
                    "failure_threshold": 3,
                    "timeout_seconds": 120,  # Longer timeout for external API
                    "success_threshold": 2
                },
                "retry_policy": {
                    "max_retries": 3,
                    "base_delay": 1.0,
                    "max_delay": 10.0,
                    "exponential_backoff": True
                },
                "instances": [
                    {
                        "id": "stripe_primary",
                        "endpoint": "https://api.stripe.com",
                        "health_check_url": "https://api.stripe.com/v1/accounts",
                        "priority": 1,
                        "max_capacity": 100
                    }
                ]
            }
        }
    
    async def initialize_services(self):
        """Initialize all high availability services and patterns"""
        
        try:
            self.logger.info("ðŸ”„ Initializing high availability services...")
            
            # Create load balancer pools
            for service_name, config in self.ha_patterns.items():
                await self._create_load_balancer_pool(service_name, config)
                await self._create_circuit_breaker(service_name, config)
                
                if "failover" in config:
                    await self._create_failover_configuration(service_name, config)
            
            self.logger.info(f"âœ… Initialized {len(self.load_balancer_pools)} HA service pools")
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to initialize HA services: {e}")
            raise
    
    async def _create_load_balancer_pool(self, service_name: str, config: Dict[str, Any]):
        """Create load balancer pool for a service"""
        
        instances = []
        for inst_config in config.get("instances", []):
            instance = ServiceInstance(
                id=inst_config["id"],
                name=service_name,
                endpoint=inst_config["endpoint"],
                health_check_url=inst_config["health_check_url"],
                priority=inst_config["priority"],
                max_capacity=inst_config["max_capacity"],
                metadata=inst_config.get("metadata", {})
            )
            instances.append(instance)
        
        lb_config = config.get("load_balancer", {})
        pool = LoadBalancerPool(
            name=service_name,
            instances=instances,
            balancing_strategy=lb_config.get("strategy", "round_robin"),
            health_check_interval=lb_config.get("health_check_interval", 30),
            sticky_sessions=lb_config.get("sticky_sessions", False),
            session_affinity_key=lb_config.get("session_affinity_key")
        )
        
        self.load_balancer_pools[service_name] = pool
        self.logger.info(f"ðŸ“¡ Created load balancer pool for {service_name} with {len(instances)} instances")
    
    async def _create_circuit_breaker(self, service_name: str, config: Dict[str, Any]):
        """Create circuit breaker for a service"""
        
        cb_config = config.get("circuit_breaker", {})
        circuit_breaker = CircuitBreaker(
            service_name=service_name,
            failure_threshold=cb_config.get("failure_threshold", 5),
            success_threshold=cb_config.get("success_threshold", 3),
            timeout_seconds=cb_config.get("timeout_seconds", 60)
        )
        
        self.circuit_breakers[service_name] = circuit_breaker
        self.logger.info(f"âš¡ Created circuit breaker for {service_name}")
    
    async def _create_failover_configuration(self, service_name: str, config: Dict[str, Any]):
        """Create failover configuration for a service"""
        
        failover_config = config.get("failover", {})
        failover = FailoverConfiguration(
            primary_pool=service_name,
            secondary_pools=failover_config.get("secondary_pools", []),
            failover_threshold=failover_config.get("failover_threshold", 2),
            auto_recovery_enabled=failover_config.get("auto_recovery", True),
            recovery_threshold=failover_config.get("recovery_threshold", 3),
            current_pool=service_name
        )
        
        self.failover_configs[service_name] = failover
        self.logger.info(f"ðŸ”„ Created failover configuration for {service_name}")
    
    async def execute_request(self, service_name: str, 
                            request_func: Callable, 
                            *args, 
                            session_key: Optional[str] = None,
                            **kwargs) -> Any:
        """
        Execute request through high availability layer with circuit breaker,
        load balancing, and automatic failover
        """
        
        # Check circuit breaker
        circuit_breaker = self.circuit_breakers.get(service_name)
        if circuit_breaker and not circuit_breaker.can_execute():
            raise Exception(f"Circuit breaker OPEN for {service_name}")
        
        # Get service instance
        pool = self.load_balancer_pools.get(service_name)
        if not pool:
            raise Exception(f"No load balancer pool found for {service_name}")
        
        instance = pool.select_instance(session_key)
        if not instance:
            # Try failover if configured
            if service_name in self.failover_configs:
                return await self._attempt_failover_request(service_name, request_func, *args, **kwargs)
            raise Exception(f"No healthy instances available for {service_name}")
        
        # Execute request
        try:
            start_time = time.time()
            result = await self._execute_with_instance(instance, request_func, *args, **kwargs)
            
            # Record success
            if circuit_breaker:
                circuit_breaker.record_success()
            
            response_time = (time.time() - start_time) * 1000
            await self._record_request_metrics(service_name, instance, True, response_time)
            
            return result
            
        except Exception as e:
            # Record failure
            if circuit_breaker:
                circuit_breaker.record_failure()
                await self._record_circuit_breaker_event(service_name, "failure", str(e))
            
            response_time = (time.time() - start_time) * 1000
            await self._record_request_metrics(service_name, instance, False, response_time)
            
            # Mark instance as unhealthy
            instance.consecutive_failures += 1
            if instance.consecutive_failures >= 3:
                instance.state = ServiceState.UNHEALTHY
                self.logger.warning(f"âš ï¸ Instance {instance.id} marked as unhealthy")
            
            # Try failover if configured
            if service_name in self.failover_configs and self.auto_failover_enabled:
                try:
                    return await self._attempt_failover_request(service_name, request_func, *args, **kwargs)
                except Exception as failover_error:
                    self.logger.error(f"âŒ Failover also failed for {service_name}: {failover_error}")
            
            raise
    
    async def _execute_with_instance(self, instance: ServiceInstance, 
                                   request_func: Callable, *args, **kwargs) -> Any:
        """Execute request with specific service instance"""
        
        # Update instance load
        instance.current_load += 1
        
        try:
            # Modify kwargs to include instance endpoint if needed
            if 'endpoint' in kwargs:
                kwargs['endpoint'] = instance.endpoint
            
            result = await request_func(*args, **kwargs)
            
            # Reset consecutive failures on success
            instance.consecutive_failures = 0
            if instance.state == ServiceState.UNHEALTHY:
                instance.state = ServiceState.HEALTHY
                self.logger.info(f"âœ… Instance {instance.id} recovered to healthy state")
            
            return result
            
        finally:
            # Update instance load
            instance.current_load = max(0, instance.current_load - 1)
    
    async def _attempt_failover_request(self, service_name: str, 
                                      request_func: Callable, *args, **kwargs) -> Any:
        """Attempt request execution with failover"""
        
        failover_config = self.failover_configs.get(service_name)
        if not failover_config:
            raise Exception(f"No failover configuration for {service_name}")
        
        # Try secondary pools
        for secondary_pool in failover_config.secondary_pools:
            secondary_lb_pool = self.load_balancer_pools.get(secondary_pool)
            if secondary_lb_pool:
                instance = secondary_lb_pool.select_instance()
                if instance and instance.state != ServiceState.FAILED:
                    try:
                        result = await self._execute_with_instance(instance, request_func, *args, **kwargs)
                        
                        # Update failover state
                        if failover_config.state != FailoverState.FAILED_OVER:
                            failover_config.state = FailoverState.FAILED_OVER
                            failover_config.current_pool = secondary_pool
                            failover_config.failover_time = datetime.utcnow()
                            
                            await self._record_failover_event(service_name, secondary_pool, "success")
                            self.logger.warning(f"ðŸ”„ FAILOVER: {service_name} failed over to {secondary_pool}")
                        
                        return result
                        
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Failover to {secondary_pool} also failed: {e}")
                        continue
        
        # If all failover attempts failed, check for degraded mode
        if self._has_degraded_mode(service_name):
            return await self._execute_degraded_mode(service_name, request_func, *args, **kwargs)
        
        raise Exception(f"All failover attempts failed for {service_name}")
    
    def _has_degraded_mode(self, service_name: str) -> bool:
        """Check if service has degraded mode configuration"""
        config = self.ha_patterns.get(service_name, {})
        return config.get("degraded_mode", {}).get("enabled", False)
    
    async def _execute_degraded_mode(self, service_name: str, 
                                   request_func: Callable, *args, **kwargs) -> Any:
        """Execute request in degraded mode"""
        
        config = self.ha_patterns.get(service_name, {})
        degraded_config = config.get("degraded_mode", {})
        
        self.logger.warning(f"ðŸ”¶ Executing {service_name} in degraded mode")
        
        # Return cached/fallback response
        fallback_response = degraded_config.get("fallback_response", {
            "message": f"{service_name} operating in degraded mode",
            "status": "limited_functionality"
        })
        
        return fallback_response
    
    async def perform_health_checks(self):
        """Perform health checks on all service instances"""
        
        for pool_name, pool in self.load_balancer_pools.items():
            for instance in pool.instances:
                await self._perform_instance_health_check(instance)
    
    async def _perform_instance_health_check(self, instance: ServiceInstance):
        """Perform health check on a specific instance"""
        
        try:
            start_time = time.time()
            
            # This would be replaced with actual health check implementation
            # For now, simulate health check
            if "health" in instance.health_check_url:
                # Simulate health check logic
                health_status = "healthy"  # Would come from actual HTTP request
            else:
                health_status = "unknown"
            
            response_time = (time.time() - start_time) * 1000
            
            # Update instance state
            instance.last_health_check = datetime.utcnow()
            
            if health_status == "healthy":
                if instance.state == ServiceState.UNHEALTHY:
                    instance.state = ServiceState.HEALTHY
                    instance.consecutive_failures = 0
                    self.logger.info(f"âœ… Instance {instance.id} health check passed - restored to healthy")
            else:
                instance.consecutive_failures += 1
                if instance.consecutive_failures >= 2:
                    instance.state = ServiceState.UNHEALTHY
                    self.logger.warning(f"âš ï¸ Instance {instance.id} health check failed - marked unhealthy")
            
            # Record health check metrics
            await self._record_health_check_metrics(instance, health_status == "healthy", response_time)
            
        except Exception as e:
            instance.consecutive_failures += 1
            instance.state = ServiceState.FAILED
            self.logger.error(f"âŒ Health check failed for {instance.id}: {e}")
    
    async def get_service_availability_status(self, service_name: str) -> Dict[str, Any]:
        """Get comprehensive availability status for a service"""
        
        pool = self.load_balancer_pools.get(service_name)
        circuit_breaker = self.circuit_breakers.get(service_name)
        failover_config = self.failover_configs.get(service_name)
        
        if not pool:
            return {"error": f"Service {service_name} not found"}
        
        # Calculate availability metrics
        healthy_instances = len(pool.get_healthy_instances())
        total_instances = len(pool.instances)
        availability_percentage = (healthy_instances / total_instances * 100) if total_instances > 0 else 0
        
        # Get recent metrics
        recent_metrics = list(self.availability_metrics[service_name])[-10:] if self.availability_metrics[service_name] else []
        
        return {
            "service_name": service_name,
            "availability_percentage": availability_percentage,
            "healthy_instances": healthy_instances,
            "total_instances": total_instances,
            "instances": [
                {
                    "id": inst.id,
                    "state": inst.state.value,
                    "current_load": inst.current_load,
                    "consecutive_failures": inst.consecutive_failures,
                    "last_health_check": inst.last_health_check.isoformat() if inst.last_health_check else None
                }
                for inst in pool.instances
            ],
            "circuit_breaker": {
                "state": circuit_breaker.state.value if circuit_breaker else "disabled",
                "failure_count": circuit_breaker.failure_count if circuit_breaker else 0,
                "can_execute": circuit_breaker.can_execute() if circuit_breaker else True
            } if circuit_breaker else None,
            "failover": {
                "state": failover_config.state.value if failover_config else "not_configured",
                "current_pool": failover_config.current_pool if failover_config else None,
                "failover_time": failover_config.failover_time.isoformat() if failover_config and failover_config.failover_time else None
            } if failover_config else None,
            "recent_performance": {
                "average_response_time_ms": statistics.mean([m["response_time"] for m in recent_metrics]) if recent_metrics else 0,
                "success_rate": (sum(1 for m in recent_metrics if m["success"]) / len(recent_metrics) * 100) if recent_metrics else 100
            },
            "load_balancer": {
                "strategy": pool.balancing_strategy,
                "sticky_sessions": pool.sticky_sessions,
                "current_index": pool.current_index
            }
        }
    
    async def get_ha_dashboard(self) -> Dict[str, Any]:
        """Get comprehensive high availability dashboard"""
        
        dashboard = {
            "timestamp": datetime.utcnow().isoformat(),
            "overall_ha_status": "healthy",
            "services": {},
            "summary": {
                "total_services": len(self.load_balancer_pools),
                "healthy_services": 0,
                "degraded_services": 0,
                "failed_services": 0,
                "active_failovers": 0,
                "open_circuit_breakers": 0
            },
            "recent_events": {
                "failovers": list(self.failover_history)[-5:],
                "circuit_breaker_events": list(self.circuit_breaker_events)[-10:]
            },
            "business_impact": {
                "revenue_critical_services_healthy": 0,
                "customer_facing_services_healthy": 0,
                "estimated_availability_score": 0.0
            }
        }
        
        total_availability = 0
        revenue_critical_count = 0
        customer_facing_count = 0
        
        for service_name in self.load_balancer_pools:
            service_status = await self.get_service_availability_status(service_name)
            dashboard["services"][service_name] = service_status
            
            # Update summary
            availability = service_status["availability_percentage"]
            total_availability += availability
            
            if availability >= 95:
                dashboard["summary"]["healthy_services"] += 1
            elif availability >= 70:
                dashboard["summary"]["degraded_services"] += 1
            else:
                dashboard["summary"]["failed_services"] += 1
            
            # Check for active failovers
            if service_status.get("failover", {}).get("state") == "failed_over":
                dashboard["summary"]["active_failovers"] += 1
            
            # Check for open circuit breakers
            if service_status.get("circuit_breaker", {}).get("state") == "open":
                dashboard["summary"]["open_circuit_breakers"] += 1
            
            # Business impact analysis
            if service_name in ["payment_system", "booking_system"]:
                revenue_critical_count += 1
                if availability >= 99:
                    dashboard["business_impact"]["revenue_critical_services_healthy"] += 1
            
            if service_name in ["payment_system", "booking_system", "ai_dashboard"]:
                customer_facing_count += 1
                if availability >= 95:
                    dashboard["business_impact"]["customer_facing_services_healthy"] += 1
        
        # Calculate overall status
        overall_availability = total_availability / len(self.load_balancer_pools) if self.load_balancer_pools else 100
        dashboard["business_impact"]["estimated_availability_score"] = overall_availability
        
        if overall_availability >= 99.9:
            dashboard["overall_ha_status"] = "excellent"
        elif overall_availability >= 99.0:
            dashboard["overall_ha_status"] = "healthy"
        elif overall_availability >= 95.0:
            dashboard["overall_ha_status"] = "degraded"
        else:
            dashboard["overall_ha_status"] = "critical"
        
        return dashboard
    
    async def trigger_manual_failover(self, service_name: str, target_pool: str) -> bool:
        """Manually trigger failover for a service"""
        
        try:
            failover_config = self.failover_configs.get(service_name)
            if not failover_config:
                self.logger.error(f"No failover configuration for {service_name}")
                return False
            
            # Update failover state
            failover_config.state = FailoverState.FAILED_OVER
            failover_config.current_pool = target_pool
            failover_config.failover_time = datetime.utcnow()
            
            await self._record_failover_event(service_name, target_pool, "manual")
            
            self.logger.warning(f"ðŸ”„ MANUAL FAILOVER: {service_name} failed over to {target_pool}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Manual failover failed for {service_name}: {e}")
            return False
    
    async def reset_circuit_breaker(self, service_name: str) -> bool:
        """Manually reset circuit breaker for a service"""
        
        try:
            circuit_breaker = self.circuit_breakers.get(service_name)
            if not circuit_breaker:
                return False
            
            circuit_breaker.state = CircuitBreakerState.CLOSED
            circuit_breaker.failure_count = 0
            circuit_breaker.success_count = 0
            circuit_breaker.half_open_calls = 0
            
            await self._record_circuit_breaker_event(service_name, "manual_reset", "Circuit breaker manually reset")
            
            self.logger.info(f"ðŸ”„ Circuit breaker reset for {service_name}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to reset circuit breaker for {service_name}: {e}")
            return False
    
    # Helper methods for metrics and events
    
    async def _record_request_metrics(self, service_name: str, instance: ServiceInstance, 
                                    success: bool, response_time: float):
        """Record request metrics"""
        
        metric = {
            "timestamp": datetime.utcnow().isoformat(),
            "service_name": service_name,
            "instance_id": instance.id,
            "success": success,
            "response_time": response_time
        }
        
        self.availability_metrics[service_name].append(metric)
    
    async def _record_health_check_metrics(self, instance: ServiceInstance, 
                                         success: bool, response_time: float):
        """Record health check metrics"""
        
        metric = {
            "timestamp": datetime.utcnow().isoformat(),
            "instance_id": instance.id,
            "health_check_success": success,
            "response_time": response_time
        }
        
        # Store in cache for dashboard access
        cache_key = f"health_check:{instance.id}"
        await cache_service.set(cache_key, json.dumps(metric), ttl=300)
    
    async def _record_failover_event(self, service_name: str, target_pool: str, trigger_type: str):
        """Record failover event"""
        
        event = {
            "timestamp": datetime.utcnow().isoformat(),
            "service_name": service_name,
            "target_pool": target_pool,
            "trigger_type": trigger_type,
            "event_type": "failover"
        }
        
        self.failover_history.append(event)
        
        # Send to monitoring
        await enhanced_sentry.capture_business_event(
            "ha_failover",
            f"Failover triggered for {service_name} to {target_pool}",
            event,
            severity=AlertSeverity.HIGH
        )
    
    async def _record_circuit_breaker_event(self, service_name: str, event_type: str, details: str):
        """Record circuit breaker event"""
        
        event = {
            "timestamp": datetime.utcnow().isoformat(),
            "service_name": service_name,
            "event_type": event_type,
            "details": details,
            "circuit_breaker_state": self.circuit_breakers[service_name].state.value
        }
        
        self.circuit_breaker_events.append(event)
        
        # Send to monitoring for critical events
        if event_type in ["failure", "circuit_open"]:
            await enhanced_sentry.capture_business_event(
                "circuit_breaker_event",
                f"Circuit breaker event for {service_name}: {event_type}",
                event,
                severity=AlertSeverity.MEDIUM
            )
    
    async def start_monitoring(self):
        """Start high availability monitoring"""
        
        if self._monitoring_active:
            return
        
        try:
            self._monitoring_active = True
            
            # Start monitoring tasks
            monitoring_tasks = [
                self._health_check_loop(),
                self._failover_recovery_loop(),
                self._circuit_breaker_maintenance_loop(),
                self._ha_metrics_collection_loop()
            ]
            
            self._monitoring_tasks = [asyncio.create_task(task) for task in monitoring_tasks]
            
            self.logger.info("ðŸ” High availability monitoring started")
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to start HA monitoring: {e}")
    
    async def _health_check_loop(self):
        """Health check monitoring loop"""
        while self._monitoring_active:
            try:
                await self.perform_health_checks()
                await asyncio.sleep(30)  # Health checks every 30 seconds
                
            except Exception as e:
                self.logger.error(f"âŒ Health check loop error: {e}")
                await asyncio.sleep(30)
    
    async def _failover_recovery_loop(self):
        """Failover recovery monitoring loop"""
        while self._monitoring_active:
            try:
                await self._check_failover_recovery()
                await asyncio.sleep(60)  # Check recovery every minute
                
            except Exception as e:
                self.logger.error(f"âŒ Failover recovery loop error: {e}")
                await asyncio.sleep(60)
    
    async def _circuit_breaker_maintenance_loop(self):
        """Circuit breaker maintenance loop"""
        while self._monitoring_active:
            try:
                await self._maintain_circuit_breakers()
                await asyncio.sleep(30)  # Check circuit breakers every 30 seconds
                
            except Exception as e:
                self.logger.error(f"âŒ Circuit breaker maintenance error: {e}")
                await asyncio.sleep(30)
    
    async def _ha_metrics_collection_loop(self):
        """HA metrics collection loop"""
        while self._monitoring_active:
            try:
                await self._collect_ha_metrics()
                await asyncio.sleep(300)  # Collect metrics every 5 minutes
                
            except Exception as e:
                self.logger.error(f"âŒ HA metrics collection error: {e}")
                await asyncio.sleep(300)
    
    async def _check_failover_recovery(self):
        """Check if failed over services can be recovered"""
        
        for service_name, failover_config in self.failover_configs.items():
            if (failover_config.state == FailoverState.FAILED_OVER and 
                failover_config.auto_recovery_enabled):
                
                # Check if primary pool is healthy again
                primary_pool = self.load_balancer_pools.get(failover_config.primary_pool)
                if primary_pool:
                    healthy_instances = primary_pool.get_healthy_instances()
                    if len(healthy_instances) > 0:
                        # Attempt recovery
                        await self._attempt_service_recovery(service_name, failover_config)
    
    async def _attempt_service_recovery(self, service_name: str, failover_config: FailoverConfiguration):
        """Attempt to recover service to primary pool"""
        
        try:
            # Test primary pool health
            primary_pool = self.load_balancer_pools.get(failover_config.primary_pool)
            if primary_pool:
                healthy_instances = primary_pool.get_healthy_instances()
                
                if len(healthy_instances) >= failover_config.recovery_threshold:
                    # Recover to primary
                    failover_config.state = FailoverState.ACTIVE
                    failover_config.current_pool = failover_config.primary_pool
                    failover_config.recovery_attempts += 1
                    
                    self.logger.info(f"âœ… Service {service_name} recovered to primary pool")
                    
                    await self._record_failover_event(service_name, failover_config.primary_pool, "auto_recovery")
        
        except Exception as e:
            self.logger.error(f"âŒ Failed to recover {service_name}: {e}")
    
    async def _maintain_circuit_breakers(self):
        """Maintain circuit breaker states"""
        
        for service_name, circuit_breaker in self.circuit_breakers.items():
            if circuit_breaker.state == CircuitBreakerState.OPEN:
                # Check if timeout has elapsed
                if (circuit_breaker.last_failure_time and 
                    (datetime.utcnow() - circuit_breaker.last_failure_time).total_seconds() > circuit_breaker.timeout_seconds):
                    circuit_breaker.state = CircuitBreakerState.HALF_OPEN
                    circuit_breaker.half_open_calls = 0
                    await self._record_circuit_breaker_event(service_name, "half_open", "Circuit breaker moved to half-open state")
    
    async def _collect_ha_metrics(self):
        """Collect and store HA metrics"""
        
        dashboard = await self.get_ha_dashboard()
        
        # Store in cache for dashboard access
        await cache_service.set("ha_dashboard", json.dumps(dashboard), ttl=300)
        
        # Log key metrics
        self.logger.info(f"ðŸ“Š HA Metrics - Overall: {dashboard['overall_ha_status']}, "
                        f"Healthy: {dashboard['summary']['healthy_services']}/{dashboard['summary']['total_services']}, "
                        f"Active Failovers: {dashboard['summary']['active_failovers']}")
    
    async def stop_monitoring(self):
        """Stop high availability monitoring"""
        
        self._monitoring_active = False
        
        for task in self._monitoring_tasks:
            task.cancel()
        
        if self._monitoring_tasks:
            await asyncio.gather(*self._monitoring_tasks, return_exceptions=True)


# Global high availability orchestrator instance
ha_orchestrator = HighAvailabilityOrchestrator()