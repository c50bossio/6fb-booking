#!/usr/bin/env python3
"""
Performance Optimization Verification Script
Tests all implemented performance optimizations to ensure they're working correctly.
"""

import asyncio
import aiohttp
import time
import json
import sys
import os
from pathlib import Path
import subprocess
import logging
from typing import Dict, List, Any

# Add the backend directory to the path
sys.path.append(str(Path(__file__).parent.parent))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerformanceVerifier:
    """Comprehensive performance optimization verification"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results = {
            'frontend_optimization': {},
            'database_optimization': {},
            'caching_optimization': {},
            'api_optimization': {},
            'monitoring_optimization': {}
        }
    
    async def verify_all(self) -> Dict[str, Any]:
        """Run all verification tests"""
        logger.info("üöÄ Starting comprehensive performance optimization verification...")
        
        await self.verify_frontend_optimizations()
        await self.verify_database_optimizations()
        await self.verify_caching_optimizations()
        await self.verify_api_optimizations()
        await self.verify_monitoring_optimizations()
        
        # Generate summary report
        return self.generate_report()
    
    async def verify_frontend_optimizations(self):
        """Verify frontend bundle optimization and dynamic imports"""
        logger.info("üì¶ Verifying frontend optimizations...")
        
        results = {
            'bundle_analyzer_config': False,
            'dynamic_loading_utility': False,
            'code_splitting_config': False,
            'compression_enabled': False
        }
        
        try:
            # Check if bundle analyzer is configured
            next_config_path = Path(__file__).parent.parent / "frontend-v2" / "next.config.js"
            if next_config_path.exists():
                with open(next_config_path, 'r') as f:
                    config_content = f.read()
                    if "withBundleAnalyzer" in config_content:
                        results['bundle_analyzer_config'] = True
                        logger.info("‚úÖ Bundle analyzer configured")
                    if "splitChunks" in config_content:
                        results['code_splitting_config'] = True
                        logger.info("‚úÖ Code splitting configured")
            
            # Check if dynamic loading utility exists
            dynamic_loading_path = Path(__file__).parent.parent / "frontend-v2" / "lib" / "dynamic-loading.tsx"
            if dynamic_loading_path.exists():
                results['dynamic_loading_utility'] = True
                logger.info("‚úÖ Dynamic loading utility created")
            
            # Test compression (if server is running)
            try:
                async with aiohttp.ClientSession() as session:
                    headers = {'Accept-Encoding': 'gzip, deflate'}
                    async with session.get(f"{self.base_url}/health", headers=headers) as response:
                        if response.headers.get('content-encoding') == 'gzip':
                            results['compression_enabled'] = True
                            logger.info("‚úÖ Response compression enabled")
            except:
                logger.warning("‚ö†Ô∏è Could not test compression (server may not be running)")
        
        except Exception as e:
            logger.error(f"‚ùå Frontend optimization verification failed: {e}")
        
        self.results['frontend_optimization'] = results
    
    async def verify_database_optimizations(self):
        """Verify database configuration and connection pooling"""
        logger.info("üóÑÔ∏è Verifying database optimizations...")
        
        results = {
            'performance_config_exists': False,
            'connection_pooling_configured': False,
            'indexes_configured': False,
            'health_check_available': False
        }
        
        try:
            # Check if performance config exists
            perf_config_path = Path(__file__).parent.parent / "database" / "performance_config.py"
            if perf_config_path.exists():
                results['performance_config_exists'] = True
                logger.info("‚úÖ Database performance config created")
                
                # Check for connection pooling configuration
                with open(perf_config_path, 'r') as f:
                    config_content = f.read()
                    if "QueuePool" in config_content and "pool_size" in config_content:
                        results['connection_pooling_configured'] = True
                        logger.info("‚úÖ Connection pooling configured")
                    if "CREATE INDEX" in config_content:
                        results['indexes_configured'] = True
                        logger.info("‚úÖ Database indexes configured")
            
            # Test database health endpoint
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"{self.base_url}/api/v2/monitoring/metrics/database") as response:
                        if response.status == 200:
                            results['health_check_available'] = True
                            logger.info("‚úÖ Database health check available")
            except:
                logger.warning("‚ö†Ô∏è Could not test database health endpoint")
        
        except Exception as e:
            logger.error(f"‚ùå Database optimization verification failed: {e}")
        
        self.results['database_optimization'] = results
    
    async def verify_caching_optimizations(self):
        """Verify Redis caching implementation"""
        logger.info("üíæ Verifying caching optimizations...")
        
        results = {
            'redis_manager_exists': False,
            'cache_decorators_available': False,
            'invalidation_strategies': False,
            'cache_health_check': False
        }
        
        try:
            # Check if Redis manager exists
            redis_manager_path = Path(__file__).parent.parent / "cache" / "redis_manager.py"
            if redis_manager_path.exists():
                results['redis_manager_exists'] = True
                logger.info("‚úÖ Redis manager created")
                
                with open(redis_manager_path, 'r') as f:
                    cache_content = f.read()
                    if "@cache_result" in cache_content:
                        results['cache_decorators_available'] = True
                        logger.info("‚úÖ Cache decorators available")
                    if "invalidate_pattern" in cache_content:
                        results['invalidation_strategies'] = True
                        logger.info("‚úÖ Cache invalidation strategies implemented")
            
            # Test cache health endpoint
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"{self.base_url}/api/v2/monitoring/metrics/cache") as response:
                        if response.status == 200:
                            results['cache_health_check'] = True
                            logger.info("‚úÖ Cache health check available")
            except:
                logger.warning("‚ö†Ô∏è Could not test cache health endpoint")
        
        except Exception as e:
            logger.error(f"‚ùå Caching optimization verification failed: {e}")
        
        self.results['caching_optimization'] = results
    
    async def verify_api_optimizations(self):
        """Verify API performance optimizations"""
        logger.info("üîå Verifying API optimizations...")
        
        results = {
            'performance_middleware_exists': False,
            'compression_middleware': False,
            'rate_limiting_middleware': False,
            'performance_monitoring': False,
            'cache_control_headers': False
        }
        
        try:
            # Check if performance middleware exists
            middleware_path = Path(__file__).parent.parent / "middleware" / "performance_middleware.py"
            if middleware_path.exists():
                results['performance_middleware_exists'] = True
                logger.info("‚úÖ Performance middleware created")
                
                with open(middleware_path, 'r') as f:
                    middleware_content = f.read()
                    if "CompressionMiddleware" in middleware_content:
                        results['compression_middleware'] = True
                        logger.info("‚úÖ Compression middleware implemented")
                    if "RateLimitMiddleware" in middleware_content:
                        results['rate_limiting_middleware'] = True
                        logger.info("‚úÖ Rate limiting middleware implemented")
                    if "PerformanceMonitoringMiddleware" in middleware_content:
                        results['performance_monitoring'] = True
                        logger.info("‚úÖ Performance monitoring middleware implemented")
                    if "CacheControlMiddleware" in middleware_content:
                        results['cache_control_headers'] = True
                        logger.info("‚úÖ Cache control middleware implemented")
        
        except Exception as e:
            logger.error(f"‚ùå API optimization verification failed: {e}")
        
        self.results['api_optimization'] = results
    
    async def verify_monitoring_optimizations(self):
        """Verify monitoring and health check endpoints"""
        logger.info("üìä Verifying monitoring optimizations...")
        
        results = {
            'monitoring_router_exists': False,
            'health_check_endpoint': False,
            'metrics_endpoints': False,
            'performance_alerts': False,
            'live_metrics': False
        }
        
        try:
            # Check if monitoring router exists
            monitoring_path = Path(__file__).parent.parent / "routers" / "performance_monitoring.py"
            if monitoring_path.exists():
                results['monitoring_router_exists'] = True
                logger.info("‚úÖ Performance monitoring router created")
            
            # Test monitoring endpoints
            endpoints_to_test = [
                ('/api/v2/monitoring/health', 'health_check_endpoint'),
                ('/api/v2/monitoring/metrics/system', 'metrics_endpoints'),
                ('/api/v2/monitoring/alerts', 'performance_alerts'),
                ('/api/v2/monitoring/live-metrics', 'live_metrics')
            ]
            
            async with aiohttp.ClientSession() as session:
                for endpoint, result_key in endpoints_to_test:
                    try:
                        async with session.get(f"{self.base_url}{endpoint}") as response:
                            if response.status in [200, 404]:  # 404 is OK if server not fully running
                                results[result_key] = True
                                logger.info(f"‚úÖ {endpoint} endpoint available")
                    except:
                        logger.warning(f"‚ö†Ô∏è Could not test {endpoint}")
        
        except Exception as e:
            logger.error(f"‚ùå Monitoring optimization verification failed: {e}")
        
        self.results['monitoring_optimization'] = results
    
    def generate_report(self) -> Dict[str, Any]:
        """Generate comprehensive verification report"""
        logger.info("üìã Generating verification report...")
        
        total_checks = 0
        passed_checks = 0
        
        for category, checks in self.results.items():
            category_total = len(checks)
            category_passed = sum(1 for check in checks.values() if check)
            total_checks += category_total
            passed_checks += category_passed
            
            logger.info(f"üìä {category}: {category_passed}/{category_total} checks passed")
        
        success_rate = (passed_checks / total_checks) * 100 if total_checks > 0 else 0
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'overall_success_rate': success_rate,
            'total_checks': total_checks,
            'passed_checks': passed_checks,
            'failed_checks': total_checks - passed_checks,
            'detailed_results': self.results,
            'recommendations': self.generate_recommendations()
        }
        
        # Print summary
        status_emoji = "‚úÖ" if success_rate >= 80 else "‚ö†Ô∏è" if success_rate >= 60 else "‚ùå"
        logger.info(f"\n{status_emoji} Performance Optimization Verification Complete!")
        logger.info(f"üìä Overall Success Rate: {success_rate:.1f}% ({passed_checks}/{total_checks})")
        
        return report
    
    def generate_recommendations(self) -> List[str]:
        """Generate recommendations based on verification results"""
        recommendations = []
        
        # Frontend recommendations
        frontend = self.results['frontend_optimization']
        if not frontend.get('bundle_analyzer_config'):
            recommendations.append("Configure bundle analyzer for production builds")
        if not frontend.get('dynamic_loading_utility'):
            recommendations.append("Implement dynamic loading for large components")
        
        # Database recommendations
        database = self.results['database_optimization']
        if not database.get('connection_pooling_configured'):
            recommendations.append("Configure database connection pooling for production")
        if not database.get('indexes_configured'):
            recommendations.append("Create performance-critical database indexes")
        
        # Caching recommendations
        caching = self.results['caching_optimization']
        if not caching.get('redis_manager_exists'):
            recommendations.append("Implement Redis caching layer")
        if not caching.get('invalidation_strategies'):
            recommendations.append("Add cache invalidation strategies")
        
        # API recommendations
        api = self.results['api_optimization']
        if not api.get('compression_middleware'):
            recommendations.append("Enable response compression middleware")
        if not api.get('rate_limiting_middleware'):
            recommendations.append("Implement rate limiting for API endpoints")
        
        # Monitoring recommendations
        monitoring = self.results['monitoring_optimization']
        if not monitoring.get('health_check_endpoint'):
            recommendations.append("Set up comprehensive health check endpoints")
        if not monitoring.get('performance_alerts'):
            recommendations.append("Configure performance alerting system")
        
        return recommendations

async def main():
    """Main verification function"""
    verifier = PerformanceVerifier()
    
    try:
        report = await verifier.verify_all()
        
        # Save report to file
        report_path = Path(__file__).parent.parent / "performance_optimization_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        logger.info(f"üìÑ Detailed report saved to: {report_path}")
        
        # Print recommendations
        if report['recommendations']:
            logger.info("\nüí° Recommendations:")
            for i, rec in enumerate(report['recommendations'], 1):
                logger.info(f"   {i}. {rec}")
        
        # Exit with appropriate code
        sys.exit(0 if report['overall_success_rate'] >= 80 else 1)
        
    except Exception as e:
        logger.error(f"‚ùå Verification failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())