# GitHub Actions Workflow for Load Testing
# Runs comprehensive load tests on pull requests and deployments
# Validates system capacity for 10,000+ concurrent users

name: Load Testing Suite

on:
  pull_request:
    branches: [ main, staging ]
    paths:
      - 'backend-v2/**'
      - 'testing/**'
      - '.github/workflows/load-testing.yml'
  
  push:
    branches: [ main ]
  
  schedule:
    # Run daily at 2 AM UTC for continuous monitoring
    - cron: '0 2 * * *'
  
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test level to run'
        required: true
        default: 'full'
        type: choice
        options:
          - smoke
          - moderate
          - full
          - stress
      target_users:
        description: 'Target concurrent users'
        required: false
        default: '10000'
        type: string

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.9'
  POSTGRES_VERSION: '14'

jobs:
  # Pre-flight checks
  preflight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      should_run_load_tests: ${{ steps.check.outputs.should_run }}
      test_level: ${{ steps.check.outputs.test_level }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Check if load tests should run
        id: check
        run: |
          # Determine test level based on trigger
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "test_level=${{ github.event.inputs.test_level }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "test_level=full" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "push" ] && [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "test_level=moderate" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            # Check if backend changes exist
            if git diff --name-only HEAD~1 HEAD | grep -E "(backend-v2|testing)" > /dev/null; then
              echo "should_run=true" >> $GITHUB_OUTPUT
              echo "test_level=smoke" >> $GITHUB_OUTPUT
            else
              echo "should_run=false" >> $GITHUB_OUTPUT
              echo "test_level=none" >> $GITHUB_OUTPUT
            fi
          else
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "test_level=none" >> $GITHUB_OUTPUT
          fi

  # Setup test environment
  setup:
    name: Setup Test Environment
    runs-on: ubuntu-latest
    needs: preflight
    if: needs.preflight.outputs.should_run_load_tests == 'true'
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: 6fb_booking_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: testing/package-lock.json
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            ~/.cache/pip
            testing/node_modules
            backend-v2/venv
          key: load-test-deps-${{ runner.os }}-${{ hashFiles('testing/package-lock.json', 'backend-v2/requirements.txt') }}
      
      - name: Install Artillery and testing dependencies
        working-directory: testing
        run: |
          npm ci
          npm install -g artillery@latest
      
      - name: Install Python dependencies
        working-directory: backend-v2
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install -r requirements.txt
      
      - name: Setup test database
        working-directory: backend-v2
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/6fb_booking_test
        run: |
          source venv/bin/activate
          alembic upgrade head
          python scripts/setup-test-data.py
      
      - name: Start backend server
        working-directory: backend-v2
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/6fb_booking_test
          REDIS_URL: redis://localhost:6379
          ENVIRONMENT: testing
        run: |
          source venv/bin/activate
          uvicorn main:app --host 0.0.0.0 --port 8000 &
          
          # Wait for server to be ready
          timeout 60 bash -c 'until curl -f http://localhost:8000/health; do sleep 2; done'
      
      - name: Verify environment
        run: |
          curl -f http://localhost:8000/health
          curl -f http://localhost:8000/api/v1/health/database

  # Smoke tests (always run for PRs)
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    needs: [preflight, setup]
    if: needs.preflight.outputs.should_run_load_tests == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: testing/package-lock.json
      
      - name: Install dependencies
        working-directory: testing
        run: npm ci
      
      - name: Run smoke tests
        working-directory: testing
        run: |
          npm run test:smoke
        env:
          CI: true
      
      - name: Upload smoke test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: smoke-test-results
          path: testing/reports/smoke-test-results.*

  # Database load tests
  database-tests:
    name: Database Load Tests
    runs-on: ubuntu-latest
    needs: [preflight, setup]
    if: needs.preflight.outputs.should_run_load_tests == 'true' && needs.preflight.outputs.test_level != 'smoke'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        uses: ./.github/actions/setup-load-test-env
      
      - name: Run database load tests
        working-directory: testing
        run: |
          node scripts/database-load-test.js
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: 6fb_booking_test
          DB_USER: postgres
          DB_PASSWORD: postgres
      
      - name: Upload database test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: database-test-results
          path: testing/reports/database-load/

  # API endpoint tests
  api-tests:
    name: API Endpoint Tests
    runs-on: ubuntu-latest
    needs: [preflight, setup]
    if: needs.preflight.outputs.should_run_load_tests == 'true' && needs.preflight.outputs.test_level != 'smoke'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        uses: ./.github/actions/setup-load-test-env
      
      - name: Run API endpoint tests
        working-directory: testing
        run: |
          npm run test:api
        env:
          CI: true
      
      - name: Upload API test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: api-test-results
          path: testing/reports/api-endpoints-results.*

  # Critical flow tests
  flow-tests:
    name: Critical Flow Tests
    runs-on: ubuntu-latest
    needs: [preflight, setup]
    if: needs.preflight.outputs.should_run_load_tests == 'true' && needs.preflight.outputs.test_level != 'smoke'
    strategy:
      matrix:
        flow: [booking, payment, calendar]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        uses: ./.github/actions/setup-load-test-env
      
      - name: Run ${{ matrix.flow }} flow tests
        working-directory: testing
        run: |
          npm run test:${{ matrix.flow }}
        env:
          CI: true
      
      - name: Upload ${{ matrix.flow }} test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: ${{ matrix.flow }}-flow-test-results
          path: testing/reports/${{ matrix.flow }}-flow-results.*

  # Gradual load tests (full and stress levels)
  gradual-load-tests:
    name: Gradual Load Tests
    runs-on: ubuntu-latest
    needs: [preflight, setup, smoke-tests]
    if: needs.preflight.outputs.should_run_load_tests == 'true' && contains(fromJson('["full", "stress"]'), needs.preflight.outputs.test_level)
    timeout-minutes: 90
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        uses: ./.github/actions/setup-load-test-env
      
      - name: Start monitoring
        working-directory: testing
        run: |
          node scripts/monitoring-collector.js &
          echo $! > monitoring.pid
        env:
          CI: true
      
      - name: Run gradual load tests
        working-directory: testing
        run: |
          node scripts/gradual-load-test.js
        env:
          CI: true
          TARGET_USERS: ${{ github.event.inputs.target_users || '10000' }}
      
      - name: Stop monitoring
        working-directory: testing
        run: |
          if [ -f monitoring.pid ]; then
            kill $(cat monitoring.pid) || true
          fi
      
      - name: Upload gradual load test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: gradual-load-test-results
          path: testing/reports/gradual-load/

  # Stress tests (stress level only)
  stress-tests:
    name: Stress Tests
    runs-on: ubuntu-latest
    needs: [preflight, setup, gradual-load-tests]
    if: needs.preflight.outputs.should_run_load_tests == 'true' && needs.preflight.outputs.test_level == 'stress'
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        uses: ./.github/actions/setup-load-test-env
      
      - name: Run stress tests
        working-directory: testing
        run: |
          npm run test:stress
        env:
          CI: true
      
      - name: Upload stress test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: stress-test-results
          path: testing/reports/stress-test-results.*

  # Performance benchmarks
  benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [preflight, setup, flow-tests]
    if: needs.preflight.outputs.should_run_load_tests == 'true' && contains(fromJson('["full", "stress"]'), needs.preflight.outputs.test_level)
    timeout-minutes: 45
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        uses: ./.github/actions/setup-load-test-env
      
      - name: Run performance benchmarks
        working-directory: testing
        run: |
          node scripts/performance-benchmarks.js
        env:
          CI: true
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-benchmark-results
          path: testing/reports/benchmarks/

  # Final report generation
  final-report:
    name: Generate Final Report
    runs-on: ubuntu-latest
    needs: [preflight, smoke-tests, database-tests, api-tests, flow-tests, gradual-load-tests, stress-tests, benchmarks]
    if: always() && needs.preflight.outputs.should_run_load_tests == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: Download all test results
        uses: actions/download-artifact@v3
        with:
          path: testing/reports/
      
      - name: Install dependencies
        working-directory: testing
        run: npm ci
      
      - name: Generate comprehensive report
        working-directory: testing
        run: |
          node scripts/generate-final-report.js --ci
        env:
          CI: true
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF: ${{ github.ref }}
          GITHUB_EVENT_NAME: ${{ github.event_name }}
      
      - name: Upload final report
        uses: actions/upload-artifact@v3
        with:
          name: final-load-test-report
          path: testing/reports/final/
      
      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const path = 'testing/reports/final/ci-summary.json';
            
            if (fs.existsSync(path)) {
              const summary = JSON.parse(fs.readFileSync(path, 'utf8'));
              
              const comment = `## ðŸš€ Load Test Results
              
              **Status**: ${summary.status === 'passed' ? 'âœ… PASSED' : 'âŒ FAILED'}
              **Production Ready**: ${summary.productionReady ? 'âœ… YES' : 'âŒ NO'}
              **Duration**: ${summary.duration}
              **Tests**: ${summary.tests.passedTests}/${summary.tests.totalTests} passed
              
              ${summary.status === 'passed' ? 
                'ðŸŽ‰ All load tests passed! System is validated for 10,000+ concurrent users.' :
                'âš ï¸ Some load tests failed. Please review the results before merging.'
              }
              
              [View detailed report](${summary.reportPath})
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
      
      - name: Set job status
        if: always()
        run: |
          if [ -f testing/reports/final/ci-summary.json ]; then
            status=$(cat testing/reports/final/ci-summary.json | jq -r '.status')
            if [ "$status" != "passed" ]; then
              echo "Load tests failed"
              exit 1
            fi
          else
            echo "No test summary found"
            exit 1
          fi

  # Performance regression detection
  regression-check:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    needs: [final-report]
    if: github.event_name == 'pull_request' && needs.final-report.result == 'success'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: Download test results
        uses: actions/download-artifact@v3
        with:
          name: final-load-test-report
          path: testing/reports/final/
      
      - name: Get baseline results
        run: |
          # Get latest results from main branch
          git checkout main
          if [ -f testing/reports/baseline/performance-baseline.json ]; then
            cp testing/reports/baseline/performance-baseline.json testing/reports/baseline.json
          else
            echo '{"baseline": "not_found"}' > testing/reports/baseline.json
          fi
          git checkout ${{ github.sha }}
      
      - name: Run regression analysis
        working-directory: testing
        run: |
          npm ci
          node scripts/regression-analysis.js
        env:
          CI: true
      
      - name: Comment regression results
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const path = 'testing/reports/regression-results.json';
            
            if (fs.existsSync(path)) {
              const results = JSON.parse(fs.readFileSync(path, 'utf8'));
              
              let comment = '## ðŸ“ˆ Performance Regression Analysis\n\n';
              
              if (results.regressions.length === 0) {
                comment += 'âœ… No performance regressions detected!';
              } else {
                comment += 'âš ï¸ Performance regressions detected:\n\n';
                results.regressions.forEach(reg => {
                  comment += `- **${reg.metric}**: ${reg.change} (threshold: ${reg.threshold})\n`;
                });
              }
              
              if (results.improvements.length > 0) {
                comment += '\nðŸŽ‰ Performance improvements:\n\n';
                results.improvements.forEach(imp => {
                  comment += `- **${imp.metric}**: ${imp.change}\n`;
                });
              }
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }